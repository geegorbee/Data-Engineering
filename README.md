# Data Engineering Portfolio

**Focus:** ETL pipelines, data processing, SQL analytics, and AWS data services

This portfolio demonstrates practical data engineering skills including pipeline architecture, data quality validation, and cloud data services‚Äîbuilt as part of my technical career transition.

---

## üìä Projects

### ETL Pipeline Demonstration
**Status:** Complete | **Date:** January 2026  
**[View Project ‚Üí](./ETL-Pipeline-Demo/)**

Python-based ETL pipeline demonstrating Extract-Transform-Load workflow for batch data processing. Implements data quality validation, transformation logic, and aggregation using Pandas‚Äîsimulating AWS Glue job architecture.

**What It Does:**
- Extracts transaction data from CSV source
- Validates data quality (null checks, status filtering, type conversion)
- Transforms data (aggregations, business logic, analytics)
- Loads processed data to output files

**Technologies:** Python, Pandas, ETL Design Patterns  
**Skills:** Pipeline orchestration, data quality checks, aggregation logic

---

## üõ†Ô∏è Technical Skills

**Data Engineering Concepts:**
- ETL/ELT workflow design
- Data quality validation and monitoring
- Batch data processing
- Data transformation and aggregation
- Pipeline orchestration and error handling

**Technologies & Tools:**
- **Languages:** Python (Pandas, data manipulation), SQL (queries, joins, aggregates), Bash scripting
- **AWS Services:** Glue (ETL fundamentals), Redshift (data warehousing), S3 (data storage and operations)
- **Version Control:** Git/GitHub
- **Development:** VS Code, Jupyter notebooks

**Recent Training (January 2026):**
- AWS Skill Builder: Introduction to AWS Glue
- AWS Skill Builder: Introduction to Amazon Redshift
- Coursera: Advanced SQL Joins (Guided Project)
- Coursera: SQL Syntax Fundamentals

---

## üéØ Career Context

I'm building data engineering skills to complement my 5 years of operations experience at Canada Revenue Agency, where I managed data verification workflows and identity-dependent datasets for teams of 12-30 agents.

**Target Roles:**
- Junior Data Engineer
- Data Analyst
- GRC Automation Engineer (security + data)
- Business Intelligence Analyst

**Why Data Engineering:**  
My background in data quality validation, compliance workflows, and operational analytics translates naturally to data engineering. I'm particularly interested in roles at the intersection of data and security‚Äîwhere data pipelines support compliance reporting, audit evidence collection, and risk analysis.

---

## üîó Related Work

**Other Portfolios:**
- **[Cybersecurity Portfolio](https://github.com/geegorbee/Cybersecurity-Portfolio)** - AWS security analysis, IAM, GRC compliance
- **[AI Portfolio](https://github.com/geegorbee/AI-Portfolio)** - Berg's AI Ordering System (Python, Pandas, Streamlit)

**Professional Background:**
- 5 years managing identity verification and access control operations
- Data quality validation and compliance monitoring
- Team leadership and stakeholder communication
- Remote work experience in high-integrity environments

---

## üì´ Contact

**Gerald Brown** 
CBS, NL, Canada

**Email:** gerald.brown@alumni.utoronto.ca  
**LinkedIn:** [linkedin.com/in/gerald-brown-63168223a](https://linkedin.com/in/gerald-brown-63168223a)  
**GitHub:** [github.com/geegorbee](https://github.com/geegorbee)

---

*This portfolio is actively growing as I complete data engineering projects and training. Check back for updates!*
